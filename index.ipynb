{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a first selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "X = df.select_dtypes(exclude=['object'])\n",
    "X.drop(columns = 'SalePrice', inplace = True)\n",
    "\n",
    "# Impute null values\n",
    "for column in X:\n",
    "    median = X[column].median()\n",
    "    X[column].fillna(value = median, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create y\n",
    "y = df[\"SalePrice\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1460 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.8792812746143956\n",
      "Test R^2: 0.45926221860708294\n",
      "Train MSE: 768735679.7667004\n",
      "Test MSE: 3266991413.4591403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "r2_train = linreg.score(X_train, y_train)\n",
    "r2_test = linreg.score(X_test, y_test)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "MSE_train = mean_squared_error(y_train, y_hat_train)\n",
    "MSE_test = mean_squared_error(y_test, y_hat_test)\n",
    "\n",
    "\n",
    "print(f\"Train R^2: {r2_train}\\nTest R^2: {r2_test}\")\n",
    "print(f\"Train MSE: {MSE_train}\\nTest MSE: {MSE_test}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalized Dataset:\n",
      "Train R^2: 0.7844565996310823\n",
      "Test R^2: 0.7592915168200037\n",
      "Train MSE : 1415594785.6217234\n",
      "Test MSE: 1326414095.8940718\n"
     ]
    }
   ],
   "source": [
    "linreg_norm = LinearRegression()\n",
    "linreg_norm.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "r2_scaled_train = linreg.score(X_scaled_train, y_scaled_train)\n",
    "r2_scaled_test = linreg.score(X_scaled_test, y_scaled_test)\n",
    "\n",
    "y_hat_scaled_train = linreg.predict(X_scaled_train)\n",
    "y_hat_scaled_test = linreg.predict(X_scaled_test)\n",
    "MSE_scaled_train = mean_squared_error(y_scaled_train, y_hat_scaled_train)\n",
    "MSE_scaled_test = mean_squared_error(y_scaled_test, y_hat_scaled_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"For Normalized Dataset:\")\n",
    "print(f\"Train R^2: {r2_scaled_train}\\nTest R^2: {r2_scaled_test}\")\n",
    "print(f\"Train MSE : {MSE_scaled_train}\\nTest MSE: {MSE_scaled_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't included dummy variables so far: let's use our \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "X_cat = df.select_dtypes(include=['object'])\n",
    "# (1460, 43) -> 43 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "# X_cat.shape = (1460, 252) -> 252 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "X_all = pd.concat([pd.DataFrame(X_scaled), X_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 289), (1460, 37), (1460, 252))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape, X_scaled.shape, X_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 289), (1460,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 289), (1095,), (365, 289), (365,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_train.shape, y_all_train.shape,X_all_test.shape, y_all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normalized Dataset:\n",
      "Train R^2: 0.9374012582923665\n",
      "Test R^2: -2.3712046253831545e+19\n",
      "Train MSE : 421833690.1805936\n",
      "Test MSE: 1.1637426878415398e+29\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y)\n",
    "\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_all_train, y_all_train)\n",
    "\n",
    "r2_all_train = linreg_all.score(X_all_train, y_all_train)\n",
    "r2_all_test = linreg_all.score(X_all_test, y_all_test)\n",
    "\n",
    "y_hat_all_train = linreg_all.predict(X_all_train)\n",
    "y_hat_all_test = linreg_all.predict(X_all_test)\n",
    "MSE_all_train = mean_squared_error(y_all_train, y_hat_all_train)\n",
    "MSE_all_test = mean_squared_error(y_all_test, y_hat_all_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"For Normalized Dataset:\")\n",
    "print(f\"Train R^2: {r2_all_train}\\nTest R^2: {r2_all_test}\")\n",
    "print(f\"Train MSE : {MSE_all_train}\\nTest MSE: {MSE_all_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting R squared values and MSE values:\n",
    "\n",
    "training R squared is high, but the testing R squared is negative --> \n",
    "this means that there is overfitting\n",
    "our predictions are very far off\n",
    "\n",
    "Also, scale of the Testing MSE is orders of magnitude higher than that of the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far far off. Similarly, the scale of the Testing MSE is orders of magnitude higher then that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lass with Alpha = 1\n",
      "Training r^2: 0.9361725727422138\n",
      "Testing r^2: -1.8123827568791495\n",
      "Training MSE: 430113424.65374255\n",
      "Testing MSE: 13802646273.941404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso_1 = Lasso(alpha=1) #Lasso is also known as the L1 norm.\n",
    "lasso_1.fit(X_all_train, y_all_train)\n",
    "\n",
    "print('Lass with Alpha = 1')\n",
    "\n",
    "print('Training r^2:', lasso_1.score(X_all_train, y_all_train))\n",
    "print('Testing r^2:', lasso_1.score(X_all_test, y_all_test))\n",
    "print('Training MSE:', mean_squared_error(y_all_train, lasso_1.predict(X_all_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_all_test, lasso_1.predict(X_all_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with Alpha = 10\n",
      "Training r^2: 0.9337413211156573\n",
      "Testing r^2: 0.8666114743521539\n",
      "Training MSE: 446496882.49028987\n",
      "Testing MSE: 654645827.285199\n"
     ]
    }
   ],
   "source": [
    "lasso_10 = Lasso(alpha=10) #Lasso is also known as the L1 norm.\n",
    "lasso_10.fit(X_all_train, y_all_train)\n",
    "print('Lasso with Alpha = 10')\n",
    "\n",
    "print('Training r^2:', lasso_10.score(X_all_train, y_all_train))\n",
    "print('Testing r^2:', lasso_10.score(X_all_test, y_all_test))\n",
    "print('Training MSE:', mean_squared_error(y_all_train, lasso_10.predict(X_all_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_all_test, lasso_10.predict(X_all_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Alpha = 1\n",
      "Training r^2: 0.9256742478900842\n",
      "Testing r^2: 0.8138413284892662\n",
      "Training MSE: 500858410.77138597\n",
      "Testing MSE: 913631790.4824659\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "ridge_1 = Ridge(alpha=1) #Lasso is also known as the L1 norm.\n",
    "ridge_1.fit(X_all_train, y_all_train)\n",
    "print('Ridge with Alpha = 1')\n",
    "print('Training r^2:', ridge_1.score(X_all_train, y_all_train))\n",
    "print('Testing r^2:', ridge_1.score(X_all_test, y_all_test))\n",
    "print('Training MSE:', mean_squared_error(y_all_train, ridge_1.predict(X_all_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_all_test, ridge_1.predict(X_all_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Alpha = 10\n",
      "Training r^2: 0.9256742478900842\n",
      "Testing r^2: 0.8138413284892662\n",
      "Training MSE: 500858410.77138597\n",
      "Testing MSE: 913631790.4824659\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "\n",
    "ridge_10 = Ridge(alpha=1) #Lasso is also known as the L1 norm.\n",
    "ridge_10.fit(X_all_train, y_all_train)\n",
    "print('Ridge with Alpha = 10')\n",
    "print('Training r^2:', ridge_10.score(X_all_train, y_all_train))\n",
    "print('Testing r^2:', ridge_10.score(X_all_test, y_all_test))\n",
    "print('Training MSE:', mean_squared_error(y_all_train, ridge_10.predict(X_all_train)))\n",
    "print('Testing MSE:', mean_squared_error(y_all_test, ridge_10.predict(X_all_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Ridge params almost zero\n",
    "ridge_1_zeros = sum(abs(ridge_1.coef_) < 10**(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_10_zeros = sum(abs(ridge_10.coef_) < 10**(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of Ridge params almost zero\n",
    "lasso_1_zeros = sum(abs(lasso_1.coef_) < 10**(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_10_zeros = sum(abs(lasso_10.coef_) < 10**(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 25, 65)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_1_zeros, ridge_10_zeros, lasso_1_zeros, lasso_10_zeros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.17367489e+01, -4.51164976e+03, -1.33303907e+03,  1.96512974e+03,\n",
       "        1.02695340e+04,  6.01766295e+03,  5.28492925e+03,  1.98423839e+03,\n",
       "        1.57048529e+03,  5.16119305e+03,  1.52489062e+03, -3.27902716e+02,\n",
       "        5.59627393e+03,  4.17732650e+03,  1.45781974e+04, -1.24922500e+03,\n",
       "        1.50680406e+04,  8.95597532e+02, -3.02561851e+02,  2.88914184e+03,\n",
       "        9.11667870e+02, -2.75498871e+03, -2.45319600e+03,  5.91629757e+03,\n",
       "        3.57808484e+03, -5.09563364e+02,  7.49982931e+03,  7.22228420e+02,\n",
       "        2.01148231e+03, -1.21816912e+02,  2.01673133e+02,  1.06260255e+03,\n",
       "        1.76038084e+03, -2.67245312e+03, -6.67861960e+02, -1.12419066e+03,\n",
       "       -3.57630171e+02, -2.66638901e+04,  1.41104010e+04,  2.98960823e+03,\n",
       "        5.75833664e+03,  3.80554423e+03, -4.99428026e+03,  4.99428026e+03,\n",
       "       -1.92592814e+03,  1.95249911e+03,  5.02311052e+02,  1.06075835e+04,\n",
       "       -1.30510121e+04,  1.94111754e+03, -6.78160643e+03,  7.12965191e+03,\n",
       "       -4.77985832e+03,  4.43181284e+03,  1.23767577e+04, -1.23767577e+04,\n",
       "        9.65894701e+02,  7.92171445e+03, -1.02171868e+04,  3.58854350e+03,\n",
       "       -2.25896587e+03, -2.55663870e+03,  5.00530310e+03, -2.44866441e+03,\n",
       "       -3.30838625e+03,  3.42540419e+03,  4.68836512e+03, -3.76632451e+03,\n",
       "       -6.02161081e+03, -8.49104083e+03,  1.57506773e+04, -2.29485114e+04,\n",
       "       -7.70217721e+03, -1.06892340e+04, -7.80554926e+03, -1.91218151e+04,\n",
       "       -1.39855587e+04,  1.27693539e+04, -1.36039900e+04,  3.09875210e+04,\n",
       "        2.56359578e+04, -1.25692202e+04, -4.58354326e+03, -8.62252812e+03,\n",
       "        2.86517517e+03,  6.12477306e+02,  4.04969273e+04, -6.08135891e+03,\n",
       "        1.20689894e+04,  1.73029015e+03,  2.59307214e+01,  1.14846577e+04,\n",
       "        1.44736498e+04, -6.65516870e+03, -2.31721768e+04,  1.49274846e+04,\n",
       "       -8.67238477e+03, -4.14228281e+03,  1.52202812e+04,  1.13392285e+04,\n",
       "        2.18231305e+04,  2.98326211e+04, -9.88029316e+04, -4.10965439e+03,\n",
       "        4.52145792e+03,  2.01758667e+04,  7.43018408e+03,  1.27818841e+04,\n",
       "        1.87157190e+03, -1.23455111e+04, -9.73812896e+03,  1.62223608e+03,\n",
       "        8.32943481e+03,  1.20721438e+04, -1.54321248e+04, -1.58220964e+04,\n",
       "       -7.70031772e+03,  1.03796759e+04,  6.55104829e+03, -2.55751436e+03,\n",
       "       -7.15451639e+03, -3.43949764e+03, -5.88537062e+03,  6.86594215e+03,\n",
       "        1.21709569e+04, -1.27591828e+05,  1.15260077e+04,  1.55149664e+04,\n",
       "        9.12763737e+03, -1.36294119e+03, -1.46125310e+03,  1.56244632e+04,\n",
       "        7.86229481e+04,  1.08975938e+04,  0.00000000e+00, -6.90982257e+03,\n",
       "        1.15114533e+04, -1.59628510e+03,  4.94537796e+03, -6.10421846e+03,\n",
       "       -1.03608952e+04,  5.11778289e+03, -6.15994633e+03, -1.81075441e+03,\n",
       "       -1.00466878e+03,  2.23247268e+03, -9.94793180e+02,  2.36703472e+02,\n",
       "        2.32487589e+02,  4.64423715e+03, -5.73627680e+02,  8.61608989e+02,\n",
       "       -1.59628510e+03,  1.36327715e+03,  5.88673332e+03,  2.06089525e+04,\n",
       "        7.51708850e+02, -1.07477897e+04,  5.37215792e+03, -1.30351769e+04,\n",
       "       -1.34952703e+04,  4.35558840e+03,  5.20822505e+03, -9.83682735e+03,\n",
       "       -8.91876646e+02,  2.71767130e+03,  2.73432980e+03,  4.07826495e+03,\n",
       "        1.39222000e+04, -5.49940130e+03, -2.74998732e+03, -5.67281134e+03,\n",
       "        9.52760395e+03,  1.98758242e+03, -7.62459860e+03, -3.50189630e+03,\n",
       "       -3.88691477e+02, -3.98161349e+03,  7.55822126e+02,  1.71311581e+03,\n",
       "       -6.84421158e+03,  1.50194763e+04, -6.66258912e+03,  1.44254876e+04,\n",
       "       -2.62628248e+03, -4.20204896e+03, -3.65992928e+03, -5.81844474e+03,\n",
       "       -3.68138674e+03,  1.43616095e+04, -9.24551215e+02,  1.98383138e+03,\n",
       "        1.53357582e+04, -1.37832627e+02, -5.00645136e+03,  1.35536817e+03,\n",
       "        3.24262882e+03,  5.75659478e+03, -4.74464896e+03,  8.63350525e+02,\n",
       "       -2.53606647e+03,  7.34262956e+03, -5.59444199e+03,  8.55925067e+03,\n",
       "       -4.74292023e+03, -1.90530182e+03,  2.78010663e+02,  8.03696255e+02,\n",
       "        6.29239722e+03,  2.00458792e+03, -3.21455073e+03, -1.67586834e+04,\n",
       "        1.08725528e+04,  1.26004584e+03,  4.98128435e+03, -3.10595018e+03,\n",
       "       -2.03453918e+03, -1.10084083e+03, -4.81062849e+02,  4.81062849e+02,\n",
       "       -1.55144463e+03,  2.43990660e+03, -3.55724709e+03,  0.00000000e+00,\n",
       "       -4.85623293e+03,  2.33262320e+04, -9.82186717e+03, -7.55283066e+03,\n",
       "       -5.95153415e+03, -1.54302679e+03, -6.20483041e+03, -4.76206078e+03,\n",
       "        2.07021972e+03,  9.26981643e+02,  0.00000000e+00,  9.51271662e+03,\n",
       "       -9.16941128e+02, -5.18282128e+03, -2.46943531e+03,  2.69688391e+03,\n",
       "       -2.29277478e+03, -1.68528868e+04, -2.65539123e+03,  5.05689552e+03,\n",
       "       -4.25493353e+03,  1.95548728e+03,  6.48127014e+02, -5.23380536e+03,\n",
       "       -6.02503993e+03, -4.84385648e+03,  2.39546800e+04, -1.89790220e+04,\n",
       "       -2.14196040e+03, -5.70938991e+03, -1.32270095e+04, -1.54352982e+04,\n",
       "        3.40735795e+03, -9.24119733e+03, -4.06063628e+03,  9.22707212e+03,\n",
       "       -7.20244494e+02, -4.75957461e+02,  1.19620196e+03,  1.07461575e+05,\n",
       "        0.00000000e+00, -1.27591828e+05, -7.16699919e+03,  2.98593346e+02,\n",
       "        1.68982763e+03, -4.53521890e+03, -4.10965439e+03,  7.90869892e+03,\n",
       "        1.64175028e+03,  0.00000000e+00, -1.01022410e+04,  9.52337177e+03,\n",
       "        1.21474692e+04,  3.95703630e+03,  1.79724228e+03, -5.63499947e+03,\n",
       "       -3.99775639e+03,  1.90598546e+03, -9.59610819e+03, -6.15455485e+03,\n",
       "        3.00440683e+03, -4.25921905e+03, -6.19196394e+03,  2.21534097e+03,\n",
       "        1.13859900e+04])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(ridge_1.coef_\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
